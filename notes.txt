batch_vb_samp_boost
num_it, abs_grad,  F, P, Trees, nr_wts, nr_wtc


batch_vb2_samp_boost
num_it, abs_grad,  F, P, Trees, nr_wts, nr_wtc, tree_node_cc


batch_vb3_samp_boost
num_it, abs_grad,  F, P, Trees, nr_wts, nr_wtc, tree_node_cc, tree_node_sc


pSampVTLogitBoost
VTLogitBoost with uniform sampling for samples, features and classes

pExtSampVTLogitBoost
VTLogitBoost, but does Extreme Sampling for features: each node uniformly samples features

pExtSamp2VTLogitBoost
pExtSampVTLogitBoost, but use weight trimming for samples, where weight is simply the absolute value of gradient

pExtSamp3VTLogitBoost
pExtSampVTLogitBoost, but use Friedman's weight trimming for samples, i.e. p*(1-p)

pExtSamp4VTLogitBoost
pExtSampVTLogitBoost, but use weight trimming for samples, where the weight is the Newton decrement = (r-p)^2 / (p*(1-p))

pVbExtSamp5VTLogitBoost
pExtSampVTLogitBoost, but use weight trimming for both samples and classes, where the weight is simply the absolute value of gradient. Verbose version

pVbExtSamp6VTLogitBoost
pVbExtSamp5VTLogitBoost, but the parameter "rs" means ratio of number of examples, instead of weights.

pVbExtSamp7VTLogitBoost
pVbExtSamp3VTLogitBoost (i.e. Friedman's weight trimming where weight is p*(1-p) ), but the parameter "rs" means ratio of number of examples, 
instead of weights. 

pVbExtSamp8VTLogitBoost
pVbExtSamp6VTLogitBoost, but do the Class Weight Trimming for each node. rc is the class count ratio.

pVbExtSamp9VTLogitBoost
pVbExtSamp8VTLogitBoost, but use all classes when fitting node values.

pVbExtSamp10VTLogitBoost
pVbExtSamp9VTLogitBoost, but rc is the weight sum ratio (instead of class count ratio). The selected class count is recorded for each node.

pVbExtSamp11VTLogitBoost
pVbExtSamp10VTLogitBoost, but record also #examples for each node (to see the actual computation needed)